# 整个流程跑起来

# 一、数据模拟

## 1、模拟日志数据

模拟数据程序

- application.yml  
- gmall2020-mock-log-2021-10-10.jar  
- logback.xml 
- path.json

执行程序生成模拟日志数据

```shell
java -jar gmall2020-mock-log-2021-10-10.jar  
-- 执行成功后会在当前目录生成一个 logs 目录
```

## 2、模拟业务数据

模拟数据程序

- application.properties
- gmall2020-mock-db-2021-11-14.jar
- gmall.sql

执行程序生成模拟业务数据

```shell
java -jar gmall2020-mock-db-2021-11-14.jar 

-- 如果是第一次执行 application.properties 文件里，如下两个字段要设置成1
mock.clear=1
mock.clear.user=1
```

# 二、数据采集

## 1、采集业务数据

根据数据流向图，业务数据采集和两个流向

流向一： mysql-》 每日全量 datax -》集群存储hadoop

流程二：mysql -》增量同步 Maxwell -》 消息缓存Kafka集群



启动如下脚本

- ha.sh start
- kafka.sh start
- flume_producer_log.sh start



